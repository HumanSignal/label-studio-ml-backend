version: "3.8"

services:
  watsonx_llm:
    container_name: watsonx_llm
    image: humansignal/ml-backend-watsonx-llm:v0
    build:
      context: .
      args:
        TEST_ENV: ${TEST_ENV}
    environment:
      # specify these parameters if you want to use basic auth for the model server
      - BASIC_AUTH_USER=
      - BASIC_AUTH_PASS=
      # set the log level for the model server
      - LOG_LEVEL=DEBUG
      # any other parameters that you want to pass to the model server
      - ANY=PARAMETER
      # specify the number of workers and threads for the model server
      - WORKERS=1
      - THREADS=8
      # specify the model directory (likely you don't need to change this)
      - MODEL_DIR=/data/models

      # Specify the Label Studio URL and API key to access
      # uploaded, local storage and cloud storage files.
      # Do not use 'localhost' as it does not work within Docker containers.
      # Use prefix 'http://' or 'https://' for the URL always.
      # Determine the actual IP using 'ifconfig' (Linux/Mac) or 'ipconfig' (Windows).
      - LABEL_STUDIO_URL=https://app.heartex.com/
      - LABEL_STUDIO_API_KEY=6fbf06a72a117816c5cfb594b8664f43d73e3850


      # Specify your WatsonX Api Key
      - WATSONX_API_KEY=Srj1SIAefzxmI6KjGuwrZuvFK10_MZVj1ZqrFpjcngYv
      # Specify the ID of your WatsonX project. Must have WML capabilities
      - WATSONX_PROJECT_ID=c5da3379-f72d-4e52-8aa0-4489ba377596
      # Specify the name of the WatsonX model you'd like to use. A full list can be found at https://ibm.github.io/watsonx-ai-python-sdk/fm_model.html#TextModels:~:text=CODELLAMA_34B_INSTRUCT_HF
      - WATSONX_MODELTYPE=GRANITE_13B_CHAT_V2

      # If you want the model to automatically predict on new data samples, provide a default prompt or the location to a default prompt.
      # If using a default prompt, set USE_INTERNAL_PROMPT to 0.
      - DEFAULT_PROMPT="Answer the following question\n\n{text}"
      - USE_INTERNAL_PROMPT_TEMPLATE=0

      # To use the webhook connection to automatically update your WatsonX.data tables, fill out the following:
      # WATSONX_ENG_USERNAME MUST be ibmlhapikey
      - WATSONX_ENG_USERNAME=ibmlhapikey

      # To get host and port information, follow the steps under Pre-requisites https://cloud.ibm.com/docs/watsonxdata?topic=watsonxdata-con-presto-serv#conn-to-prestjava.
      # You can stop once you get the host and port information, as we'll use the same API key for all of the work in this project.
      - WATSONX_ENG_HOST=eb6ba7e7-fe3d-4f70-9ff0-a5d87523814b.co1u05ot0jqujbai8j2g.lakehouse.appdomain.cloud
      - WATSONX_ENG_PORT=30312
      # The name of the catalog that you'll insert your data into
      - WATSONX_CATALOG=iceberg_data
      # The name of the schema within the catalog that you'll insert your data into
      - WATSONX_SCHEMA=_new_table
      - WATSONX_TABLE=test_insert_2


    ports:
      - "9090:9090"
    volumes:
      - "./data/server:/data"
